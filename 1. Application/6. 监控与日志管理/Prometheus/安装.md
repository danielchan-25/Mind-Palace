---
title: "Prometheus"

---

# 安装

```shell
# 创建用户
groupadd prometheus
useradd prometheus -g prometheus -s /sbin/nologin

tar -xvf prometheus-2.36.2.linux-arm64.tar.gz
mv prometheus-2.36.2.linux-arm64 prometheus
./prometheus --version
./prometheus --config.file="./prometheus.yml" &
ss -tnalp | grep 9090

# 可按实际情况修改web端口
./prometheus --config.file="./prometheus.yml" --web.listen-address=:19090 &
```

# 配置文件

配置文件路径：`prometheus/prometheus.yml`
```yml
global: # 全局配置
  scrape_interval: 10s # 默认抓取周期，单位为：ms，
  scrape_timeout: 10s # 拉取超时时间
  evaluation_interval: 15s #估算规则的默认周期
 
alerting: # 告警配置
  alertmanagers:
  - static_configs:
    - targets: ["localhost:9093"]
 
rule_files: # 规则文件
  # - "first_rules.yml"
  # - "second_rules.yml"
 
scrape_configs: # 拉取配置
  - job_name: 'prometheus'
    static_configs:
    - targets: ['localhost:9090']
```
其大致可分为四部分：
- `global`：全局配置，其中`scrape_interval`表示抓取一次数据的间隔时间，`evaluation_interval`表示进行告警规则检测的间隔时间；
- `alerting`：告警管理器（Alertmanager）的配置
- `rule_files`：告警规则
- `scrape_configs`：抓取监控信息的目标。一个`job_name`就是一个目标，其`targets`就是采集信息的IP和端口。这里默认监控了Prometheus自己，可以通过修改这里来修改Prometheus的监控端口。Prometheus的每个exporter都会是一个目标，它们可以上报不同的监控信息，比如机器状态，或者mysql性能等等，不同语言sdk也会是一个目标，它们会上报你自定义的业务监控信息。


# 节点安装

- 监控 Linux 主机，使用 `node_exporter`

- 监控 Windows 主机，使用 `windows_exporter`

## node-exporter
> 下载地址: [Node](https://github.com/prometheus/node_exporter/releases)

`node_exporter` 是 `Prometheus` 的指标数据收集组件。

它负责从目标 Jobs 收集数据，并把收集到的数据转换为Prometheus支持的时序数据格式。

和传统的指标数据收集组件不同的是，他只负责收集，并不向Server端发送数据，而是等待 Prometheus Server 主动抓取

`node_exporter` 默认的抓取url地址：`http://ip:9100/metrics` 

`node_exporter` 用于采集 node 的运行指标，包括 node 的 **cpu、load、filesystem、meminfo、network** 等基础监控指标，类似于 `zabbix` 监控系统的的 `zabbix-agent`

```shell
wget https://github.com/prometheus/node_exporter/releases/download/v0.17.0/node_exporter-0.17.0.linux-amd64.tar.gz
tar -xvf node_exporter-0.17.0.linux-amd64.tar.gz
cd node_exporter-0.17.0.linux-amd64
./node_exporter
nohup ./node_exporter > /dev/null &	# 后台运行
```

其它参数

```shell
# 修改默认端口
./node_exporter --web.listen-address=":9600"
# 修改metris路径，默认为 /metrics
./node_exporter --web.telemetry-path="/test_metrics"
# 最大并行请求数，默认为40，0为不限制
./node_exporter --web.max-requests=40
# 日志等级: [debug, info, warn, error, fatal]
./node_exporter --log.level="info"
# 置日志打印target和格式: [logfmt, json]
./node_exporter --log.format=logfmt
# 各个metric对应的参数
./node_exporter --collector.{metric-name} 
```

在 prometheus 添加 node 节点：修改 `prometheus.yml` 添加配置文件

```yml
scrape_configs:
 - job_name: 'node'
static_configs:
 - targets: ['localhost:9090']
```

其中最重要的参数就是 `--collector.<name>`

通过该参数可以启用我们收集的功能模块，`node_exporter` 会默认采集一些模块，要禁用这些默认启用的收集器可以通过 `--no-collector.<name>` 标志来禁用

如果只启用某些特定的收集器，基于先使用 `--collector.disable-defaults` 标志禁用所有默认的，然后在通过指定具体的收集器 `--collector.<name>` 来进行启用。

## windows-exporter
> 下载地址：[windows_exporter](https://github.com/prometheus-community/windows_exporter)

```powershell
.\windows_exporter-0.21.0-amd64.exe  # 启动
```


# 模块安装

## process exporter

进程监控模块。

```shell
tar -xvf process-exporter-0.7.10.linux-amd64.tar.gz
cd process-exporter-0.7.10.linux-amd64/

# 详细参数见 `-h`，一般直接启动即可。
./process-exporter  # 启动
```

---

> 参考文档
>
> 安装配置：https://www.cnblogs.com/sparkdev/p/7637583.html
